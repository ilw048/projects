{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Требуется обучить модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Построить модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import transformers as ppb\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score as f1, confusion_matrix, recall_score as recall, precision_score as precision\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier, cv, Pool\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=1):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(1)\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим датасет с отзывами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dataset = pd.read_csv('datasets/toxic_comments.csv').copy()\n",
    "except:\n",
    "    dataset = pd.read_csv('/datasets/toxic_comments.csv').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6           COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
       "12     Hey... what is it..\\n@ | talk .\\nWhat is it......\n",
       "16     Bye! \\n\\nDon't look, come or think of comming ...\n",
       "42     You are gay or antisemmitian? \\n\\nArchangel WH...\n",
       "43              FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!\n",
       "44     I'm Sorry \\n\\nI'm sorry I screwed around with ...\n",
       "51     GET FUCKED UP. GET FUCKEEED UP.  GOT A DRINK T...\n",
       "55     Stupid peace of shit stop deleting my stuff as...\n",
       "56     =Tony Sidaway is obviously a fistfuckee. He lo...\n",
       "58     My Band Page's deletion. You thought I was gon...\n",
       "59     Why can't you believe how fat Artie is? Did yo...\n",
       "65     All of my edits are good.  Cunts like you who ...\n",
       "79     Hi! I am back again!\\nLast warning!\\nStop undo...\n",
       "86     Would you both shut up, you don't run wikipedi...\n",
       "105           A pair of jew-hating weiner nazi schmucks.\n",
       "151    \"\\n\\nSORRY PUCK BUT NO ONE EVER SAID DICK WAS ...\n",
       "159    \"\\n\\nUNBLOCK ME OR I'LL GET MY LAWYERS ON TO Y...\n",
       "168    You should be fired, you're a moronic wimp who...\n",
       "176    I think that your a Fagget get a oife and burn...\n",
       "179    REPLY ABOVE:\\nThat was me, loser. The UN defin...\n",
       "181    you are a stupid fuck \\n\\nand your mother's cu...\n",
       "201    Your blatant POV pushing \\n\\nNeither of you gu...\n",
       "206    Give me a permanat block raseac....!!! remembe...\n",
       "211                Fuck you, block me, you faggot pussy!\n",
       "218    Kill all niggers. \\n\\nI have hard, that others...\n",
       "231    Burn Deck \\n\\nIf that'd guy's burn deck is lik...\n",
       "238    u r a tw@ fuck off u gay boy.U r smelly.Fuck u...\n",
       "268                         Atheism is full of bias shit\n",
       "278    Hey why you are spreading misconceptions and t...\n",
       "286    \"\\n\\nAnd you are? Let me know when you've craw...\n",
       "295    this user is such a worthless goddamn faggot f...\n",
       "298    Fuck off\\n\\nYou are NOT an administrator. You ...\n",
       "300    Well you are ridiculous, in fact I suspect tha...\n",
       "312    \"\\n\\n Fuck you \\n\\n  Fuck you award go fuck yo...\n",
       "318    Keep your eye on it, no one cares, OK? People ...\n",
       "324    MATT HARDY IS SO FUCKY!!!''Italic text[[Media:...\n",
       "330    God is dead\\nI don't mean to startle anyone bu...\n",
       "335    Have you seen the reference to their claim, yo...\n",
       "342    Thank you \\nHei, it's me, the William Hope fan...\n",
       "344    Fuck you \\n\\n-User:The Bohemian Shinobis yeah,...\n",
       "392    Dear Mokele,\\nYou have no right to tell people...\n",
       "415    Thank you for your RACIST experimenting with t...\n",
       "423                     Be careful who you call a moron.\n",
       "429    Gay \\n\\nThe existence of CDVF is further proof...\n",
       "437    I NEVER FUCKING MADE THIS MOTHER FUCKING ARTIC...\n",
       "439    Fucked with the wrong muchacho.  21:19, July 2...\n",
       "442         Hi \\n\\nIm a fucking bitch.\\n\\n50.180.208.181\n",
       "451           Add Mobile porn as additional WP:ALSO link\n",
       "476    F**K ALL RIDES AT WORLDS OF FUN  \\n\\nI hate al...\n",
       "497    \"\"\"Nazi filth\"\" is impolite  04:27, 20 Jan 200...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.query('toxic == 1')['text'].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[['text', 'toxic']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Балансировка классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предварительно было опробовано несколько моделей. Выяснилось, что в датасете присутствует проблема с дисбалансом классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10161213369158527"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['toxic'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Негативные комментарии составляют 10% всего датасета, учтем это в дальнейшем и реализуем увеличение обучающей выборки, когда получим эмбеддинги от BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Очистка комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию для очистки текста от лишних символов, используя регулярные выражения. Далее будем использовать ее через `.apply()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z ]', ' ', text) \n",
    "    return \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим ее работоспособность:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Explanation\\nWhy the edits made under my usern...\n",
       "1    D'aww! He matches this background colour I'm s...\n",
       "2    Hey man, I'm really not trying to edit war. It...\n",
       "3    \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4    You, sir, are my hero. Any chance you remember...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Explanation Why the edits made under my userna...\n",
       "1    D aww He matches this background colour I m se...\n",
       "2    Hey man I m really not trying to edit war It s...\n",
       "3    More I can t make any real suggestions on impr...\n",
       "4    You sir are my hero Any chance you remember wh...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['text'][:5].apply(clear_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Остаются только символы латиницы, функция работает корректно.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание эмбеддингов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем предобученную модель `ToxicBERT` и токенизатор, с помощью них будем создавать признаки для наших стандартных моделей классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "##для BERT вместо distilBERT\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "#Загрузка модели и токенизатора\n",
    "#tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "#model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"unitary/toxic-bert\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"unitary/toxic-bert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь начнём преобразование текстов в эмбеддинги.** <br>\n",
    "Функция ниже генерирует подвыборку из изначально обработанного датасета, производит токенизацию, а также возвращает таргеты для данной подвыборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparation(dataset, sample_size):\n",
    "    data = dataset.sample(sample_size).reset_index(drop=True).copy()\n",
    "    data['text'] = data['text'].apply(clear_text)\n",
    "    \n",
    "    tokenized = data['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=128, \n",
    "                                                               padding=True, truncation=True)))\n",
    "    max_len = 0\n",
    "    for i in tokenized.values:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "            \n",
    "    padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "    return padded, data['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее обработанный датасет передается в BERT, эмбеддинги поочередно генерируются и сохраняются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20cba3873da647c38a768eafbd7ec98c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 30s, sys: 1min 5s, total: 11min 35s\n",
      "Wall time: 4min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "set_seed(41)\n",
    "\n",
    "sample_size = 5000\n",
    "embeddings = []\n",
    "\n",
    "padded, target = preparation(dataset, sample_size)\n",
    "dataloader = DataLoader(torch.tensor(padded), batch_size=20)\n",
    "#attention_mask = np.where(padded != 0, 1, 0)\n",
    "    \n",
    "for batch in notebook.tqdm(dataloader):\n",
    "    attention_mask_batch = torch.LongTensor(np.where(batch != 0, 1, 0))\n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "       \n",
    "    embeddings.append(batch_embeddings[0].numpy())\n",
    "    #embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "    del batch\n",
    "    del attention_mask_batch\n",
    "    del batch_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.6577835 , -9.195709  , -8.637882  , -8.82751   , -8.501408  ,\n",
       "        -8.801255  ],\n",
       "       [ 1.6300064 , -5.4017816 , -2.4157476 , -3.535969  , -2.6170852 ,\n",
       "        -5.297613  ],\n",
       "       [-7.0951786 , -9.149456  , -8.664189  , -9.103351  , -8.610858  ,\n",
       "        -8.887666  ],\n",
       "       ...,\n",
       "       [-7.07103   , -9.120788  , -8.5948305 , -9.088688  , -8.618527  ,\n",
       "        -8.858386  ],\n",
       "       [-7.277208  , -9.042899  , -8.625817  , -8.869639  , -8.613976  ,\n",
       "        -8.8847885 ],\n",
       "       [-0.84738773, -8.1565    , -5.553962  , -6.65841   , -4.136997  ,\n",
       "        -7.0153437 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.array(target).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Соотношение длин массивов соблюдено, теперь можно разбить выборки на трейн, тест и сделать upsample обучающей выборки.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat=1):\n",
    "    features, target = pd.DataFrame(features), pd.Series(target)\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=1)\n",
    "    \n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также воспользуемся стратификацией, чтобы в тестовой выборке гарантированно сохранилось соотношение классов, представленное в исходном датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=1, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = upsample(x_train, y_train, repeat=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4721663313212609"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10066666666666667"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь в обучающей выборке примерно равное соотношение классов, а в тестовой реально наблюдающееся по датасету.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение. Кросс-валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модели логистической регрессии, случайного леса и градиентный бустинг CatBoost. Балансировку классов в них проводить уже не требуется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(y_true, y_pred):\n",
    "    print('f1 =', format(f1(y_true, y_pred), '.2f'))\n",
    "    print('Precision =', format(precision(y_true, y_pred), '.3f'))\n",
    "    print('Recall =', format(recall(y_true, y_pred), '.3f'))\n",
    "    print(confusion_matrix(y_true, y_pred).ravel(), '\\n  tn  fp  fn  tp') #tn fp fn tp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV 1/3] END ......................max_iter=500;, score=0.978 total time=   0.1s\n",
      "[CV 2/3] END ......................max_iter=500;, score=0.980 total time=   0.0s\n",
      "[CV 3/3] END ......................max_iter=500;, score=0.979 total time=   0.0s\n",
      "CPU times: user 676 ms, sys: 8.11 ms, total: 684 ms\n",
      "Wall time: 107 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(),\n",
       "             param_grid={'max_iter': [500]}, scoring='f1', verbose=3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lg = LogisticRegression()\n",
    "\n",
    "lg_grid = GridSearchCV(lg, param_grid={'max_iter': [500]}, cv=3, verbose=3, scoring='f1')\n",
    "\n",
    "lg_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score = 0.979\n"
     ]
    }
   ],
   "source": [
    "print(f'F1_score = {(lg_grid.best_score_):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.26 s, sys: 469 ms, total: 9.72 s\n",
      "Wall time: 8.64 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [2, 4, 6, 8],\n",
       "                         'n_estimators': [100, 150, 200]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "set_seed(1)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "param_grid = {'n_estimators': [100, 150, 200], \n",
    "              'max_depth': [i for i in range(2,9,2)]}\n",
    "\n",
    "rf_grid = GridSearchCV(rf, param_grid=param_grid, cv=3, scoring='f1', verbose=0)\n",
    "\n",
    "rf_grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score = 0.990\n",
      "{'max_depth': 8, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(f'F1_score = {rf_grid.best_score_:.3f}')\n",
    "print(rf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный бустинг CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train = Pool(x_train, y_train)\n",
    "cat_model = cat = CatBoostClassifier(verbose=0)\n",
    "\n",
    "cat_params = {'learning_rate': [0.1, 0.2, 0.3],\n",
    "              'n_estimators': [100, 200],\n",
    "              'depth': [2, 3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.04668815865\n",
      "bestIteration = 99\n",
      "\n",
      "0:\tloss: 0.0466882\tbest: 0.0466882 (0)\ttotal: 198ms\tremaining: 2.18s\n",
      "\n",
      "bestTest = 0.03722060363\n",
      "bestIteration = 99\n",
      "\n",
      "1:\tloss: 0.0372206\tbest: 0.0372206 (1)\ttotal: 322ms\tremaining: 1.61s\n",
      "\n",
      "bestTest = 0.03506341939\n",
      "bestIteration = 92\n",
      "\n",
      "2:\tloss: 0.0350634\tbest: 0.0350634 (2)\ttotal: 465ms\tremaining: 1.4s\n",
      "\n",
      "bestTest = 0.0391660981\n",
      "bestIteration = 199\n",
      "\n",
      "3:\tloss: 0.0391661\tbest: 0.0350634 (2)\ttotal: 724ms\tremaining: 1.45s\n",
      "\n",
      "bestTest = 0.03343062253\n",
      "bestIteration = 192\n",
      "\n",
      "4:\tloss: 0.0334306\tbest: 0.0334306 (4)\ttotal: 972ms\tremaining: 1.36s\n",
      "\n",
      "bestTest = 0.03286884881\n",
      "bestIteration = 184\n",
      "\n",
      "5:\tloss: 0.0328688\tbest: 0.0328688 (5)\ttotal: 1.24s\tremaining: 1.24s\n",
      "\n",
      "bestTest = 0.03598275881\n",
      "bestIteration = 99\n",
      "\n",
      "6:\tloss: 0.0359828\tbest: 0.0328688 (5)\ttotal: 1.36s\tremaining: 970ms\n",
      "\n",
      "bestTest = 0.03047267087\n",
      "bestIteration = 96\n",
      "\n",
      "7:\tloss: 0.0304727\tbest: 0.0304727 (7)\ttotal: 1.52s\tremaining: 760ms\n",
      "\n",
      "bestTest = 0.03025517205\n",
      "bestIteration = 96\n",
      "\n",
      "8:\tloss: 0.0302552\tbest: 0.0302552 (8)\ttotal: 1.65s\tremaining: 551ms\n",
      "\n",
      "bestTest = 0.03066206391\n",
      "bestIteration = 199\n",
      "\n",
      "9:\tloss: 0.0306621\tbest: 0.0302552 (8)\ttotal: 1.98s\tremaining: 397ms\n",
      "\n",
      "bestTest = 0.02862482398\n",
      "bestIteration = 121\n",
      "\n",
      "10:\tloss: 0.0286248\tbest: 0.0286248 (10)\ttotal: 2.23s\tremaining: 202ms\n",
      "\n",
      "bestTest = 0.028867594\n",
      "bestIteration = 146\n",
      "\n",
      "11:\tloss: 0.0288676\tbest: 0.0286248 (10)\ttotal: 2.52s\tremaining: 0us\n",
      "Estimating final quality...\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.0490984904\n",
      "bestIteration = 99\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.02636663326\n",
      "bestIteration = 182\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.02373730236\n",
      "bestIteration = 156\n",
      "\n",
      "CPU times: user 20.8 s, sys: 1.56 s, total: 22.3 s\n",
      "Wall time: 3.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "set_seed(1)\n",
    "\n",
    "cat_grid_search = cat_model.grid_search(cat_params, cat_train, cv=3, partition_random_seed=0, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'depth': 3, 'iterations': 200, 'learning_rate': 0.2}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_grid_search['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.9889415482\n",
      "bestIteration = 68\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.9910290237\n",
      "bestIteration = 111\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.9936440678\n",
      "bestIteration = 108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_data = cv(\n",
    "    params={'depth': 3, 'iterations': 200, 'learning_rate': 0.2, 'loss_function': 'Logloss', 'eval_metric' : 'F1'},\n",
    "    pool=cat_train,\n",
    "    fold_count=3,\n",
    "    partition_random_seed=0,\n",
    "    plot=False,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Финальный скор:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score = 0.9883\n"
     ]
    }
   ],
   "source": [
    "print('F1_score =', round(cv_data['test-F1-mean'].mean(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.3812395\ttotal: 3.33ms\tremaining: 664ms\n",
      "50:\tlearn: 0.0388910\ttotal: 81.7ms\tremaining: 239ms\n",
      "100:\tlearn: 0.0272673\ttotal: 155ms\tremaining: 152ms\n",
      "150:\tlearn: 0.0215978\ttotal: 228ms\tremaining: 74.1ms\n",
      "199:\tlearn: 0.0180508\ttotal: 300ms\tremaining: 0us\n",
      "CPU times: user 437 ms, sys: 406 ms, total: 842 ms\n",
      "Wall time: 316 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cat = CatBoostClassifier(iterations=200, depth=2, learning_rate=0.2, verbose=50)\n",
    "\n",
    "cat.fit(x_train, y_train)\n",
    "cat_pred = cat.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score = 0.979 - Логистическая регрессия\n",
      "F1_score = 0.990 - Случайный лес\n",
      "F1_score = 0.988 - CatBoost\n"
     ]
    }
   ],
   "source": [
    "print(f'F1_score = {(lg_grid.best_score_):.3f} - Логистическая регрессия')\n",
    "print(f'F1_score = {rf_grid.best_score_:.3f} - Случайный лес')\n",
    "print('F1_score =', round(cv_data['test-F1-mean'].mean(), 3), '- CatBoost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Все модели удовлетворяют требованию к результату f1-меры выше 0.75, и у всех примерно одинаковый результат на кросс-валидации. Для окончательного тестирования выберем модель случайного леса — она обладает наилучшим качеством и при этом достаточно быстрая.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель случайного леса со следующими параметрами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score = 0.990\n",
      "{'max_depth': 8, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(f'F1_score = {rf_grid.best_score_:.3f}')\n",
    "print(rf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**На тестовой выборке:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum() #всего негативных отзывов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 = 0.92\n",
      "Precision = 0.903\n",
      "Recall = 0.927\n",
      "[1334   15   11  140] \n",
      "  tn  fp  fn  tp\n"
     ]
    }
   ],
   "source": [
    "scores(y_test, rf_grid.best_estimator_.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество метрики `f1 = 0.92`, модель отлично справляется с отловом токсичных комментариев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несмотря на обилие данных, нейронной сети `ToxicBERT` хватает даже 1000 текстов, чтобы дальнейшие модели на полученных эмбеддингах хорошо выявляли негативные сообщения. Главная проблема заключалась в устранении дисбаланса классов, — если модель не будет видеть достаточно примеров какого-либо класса, будет сложно обучить ее на высокое значение метрики. Наилучшей оказалась модель случайного леса глубиной 8 и количеством деревьев 200 — `f1_test = 0.92`. Модель хорошо выявляет как положительные, так и отрицательные классы. Из 151 негативного комментария не было выявлено всего 11 (FN=11), это составляет ~7%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   }, 
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
